# heart_disease_prediction.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings
warnings.filterwarnings('ignore')

# Set style
sns.set(style=whitegrid)

print(Heart Disease Prediction using Random Forestn)

# ==================== 1. Load Dataset ====================
url = httpsarchive.ics.uci.edumlmachine-learning-databasesheart-diseaseprocessed.cleveland.data
columns = [
    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',
    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'
]
data = pd.read_csv(url, names=columns)

print(fDataset loaded {data.shape[0]} samples, {data.shape[1]} features)
print(data.head())

# ==================== 2. Data Preprocessing ====================
# Replace missing values ('') with NaN
data = data.replace('', np.nan)

# Convert to numeric
for col in data.columns
    data[col] = pd.to_numeric(data[col])

# Handle missing values (simple drop rows with NaN in critical columns)
print(fMissing valuesn{data.isnull().sum()})
data = data.dropna()

# Convert target 0 = no disease, 1 = disease (combine 1,2,3,4 into 1)
data['target'] = data['target'].apply(lambda x 1 if x  0 else 0)

print(fClasses distributionn{data['target'].value_counts()})

# ==================== 3. Exploratory Data Analysis ====================
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.countplot(x='target', data=data, palette='viridis')
plt.title('Heart Disease Distribution')
plt.xlabel('0 No Disease, 1 Disease')

plt.subplot(1, 2, 2)
sns.histplot(data['age'], bins=20, kde=True, color='skyblue')
plt.title('Age Distribution')

plt.tight_layout()
plt.show()

# Correlation heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Feature Correlation Matrix')
plt.show()

# ==================== 4. Feature & Target Split ====================
X = data.drop('target', axis=1)
y = data['target']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print(fTraining samples {X_train.shape[0]}, Test samples {X_test.shape[0]})

# ==================== 5. Model Training ====================
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print(Model trained Random Forest Classifier)

# ==================== 6. Predictions & Evaluation ====================
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(fnAccuracy {accuracy.4f})

print(nClassification Report)
print(classification_report(y_test, y_pred, target_names=['No Disease', 'Disease']))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Feature Importance
importances = model.feature_importances_
feat_names = X.columns
indices = np.argsort(importances)[-1]

plt.figure(figsize=(10, 6))
sns.barplot(x=importances[indices], y=feat_names[indices], palette='magma')
plt.title('Feature Importance')
plt.xlabel('Importance Score')
plt.show()

print(nTop 5 Important Features)
for i in range(5)
    print(f{i+1}. {feat_names[indices[i]]} {importances[indices[i]].4f})

print(nProject Complete! Model can predict heart disease risk.)